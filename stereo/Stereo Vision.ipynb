{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stereo Vision\n",
    "\n",
    "https://github.com/LearnTechWithUs/Stereo-Vision/blob/master/Main_Stereo_Vision_Prog.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package importation\n",
    "import numpy as np\n",
    "import cv2\n",
    "from openpyxl import Workbook # Used for writing data into an Excel file\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering\n",
    "kernel= np.ones((3,3),np.uint8)\n",
    "\n",
    "def coords_mouse_disp(event,x,y,flags,param):\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        #print x,y,disp[y,x],filteredImg[y,x]\n",
    "        average=0\n",
    "        for u in range (-1,2):\n",
    "            for v in range (-1,2):\n",
    "                average += disp[y+u,x+v]\n",
    "        average=average/9\n",
    "        Distance= -593.97*average**(3) + 1506.8*average**(2) - 1373.1*average + 522.06\n",
    "        Distance= np.around(Distance*0.01,decimals=2)\n",
    "        print('Distance: '+ str(Distance)+' m')\n",
    "        \n",
    "# This section has to be uncommented if you want to take mesurements and store them in the excel\n",
    "#       ws.append([counterdist, average])\n",
    "#       print('Measure at '+str(counterdist)+' cm, the dispasrity is ' + str(average))\n",
    "#       if (counterdist <= 85):\n",
    "#           counterdist += 3\n",
    "#       elif(counterdist <= 120):\n",
    "#           counterdist += 5\n",
    "#       else:\n",
    "#           counterdist += 10\n",
    "#       print('Next distance to measure: '+str(counterdist)+'cm')\n",
    "\n",
    "# Mouseclick callback\n",
    "wb=Workbook()\n",
    "ws=wb.active  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distortion Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting calibration for the 2 cameras... \n",
      "Cameras Ready to use\n"
     ]
    }
   ],
   "source": [
    "#*************************************************\n",
    "#***** Parameters for Distortion Calibration *****\n",
    "#*************************************************\n",
    "\n",
    "# Termination criteria\n",
    "criteria =(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "criteria_stereo= (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Prepare object points\n",
    "objp = np.zeros((9*6,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all images\n",
    "objpoints = []   # 3d points in real world space\n",
    "imgpointsR = []   # 2d points in image plane\n",
    "imgpointsL = []\n",
    "\n",
    "img_dir = 'C:/Users/markl/startup/raw-images/Calibration/'\n",
    "# Start calibration from the camera\n",
    "print('Starting calibration for the 2 cameras... ')\n",
    "# Call all saved images\n",
    "for i in range(18,156,2):   # Put the amount of pictures you have taken for the calibration inbetween range(0,?) wenn starting from the image number 0\n",
    "    t= str(i)\n",
    "    ChessImaR= cv2.imread(img_dir + 'R_Image'+t+'.jpg',0)    # Right side\n",
    "    ChessImaL= cv2.imread(img_dir + 'L_Image'+t+'.jpg',0)    # Left side\n",
    "    retR, cornersR = cv2.findChessboardCorners(ChessImaR,\n",
    "                                               (9,6),None)  # Define the number of chees corners we are looking for\n",
    "    retL, cornersL = cv2.findChessboardCorners(ChessImaL,\n",
    "                                               (9,6),None)  # Left side\n",
    "    if (True == retR) & (True == retL):\n",
    "        objpoints.append(objp)\n",
    "        cv2.cornerSubPix(ChessImaR,cornersR,(11,11),(-1,-1),criteria)\n",
    "        cv2.cornerSubPix(ChessImaL,cornersL,(11,11),(-1,-1),criteria)\n",
    "        imgpointsR.append(cornersR)\n",
    "        imgpointsL.append(cornersL)\n",
    "\n",
    "# Determine the new values for different parameters\n",
    "#   Right Side\n",
    "retR, mtxR, distR, rvecsR, tvecsR = cv2.calibrateCamera(objpoints,\n",
    "                                                        imgpointsR,\n",
    "                                                        ChessImaR.shape[::-1],None,None)\n",
    "hR,wR= ChessImaR.shape[:2]\n",
    "OmtxR, roiR= cv2.getOptimalNewCameraMatrix(mtxR,distR,\n",
    "                                                   (wR,hR),1,(wR,hR))\n",
    "\n",
    "#   Left Side\n",
    "retL, mtxL, distL, rvecsL, tvecsL = cv2.calibrateCamera(objpoints,\n",
    "                                                        imgpointsL,\n",
    "                                                        ChessImaL.shape[::-1],None,None)\n",
    "hL,wL= ChessImaL.shape[:2]\n",
    "OmtxL, roiL= cv2.getOptimalNewCameraMatrix(mtxL,distL,(wL,hL),1,(wL,hL))\n",
    "\n",
    "print('Cameras Ready to use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stereo Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************\n",
    "#***** Calibrate the Cameras for Stereo *****\n",
    "#********************************************\n",
    "\n",
    "# StereoCalibrate function\n",
    "flags = 0\n",
    "flags |= cv2.CALIB_FIX_INTRINSIC\n",
    "#flags |= cv2.CALIB_FIX_PRINCIPAL_POINT\n",
    "#flags |= cv2.CALIB_USE_INTRINSIC_GUESS\n",
    "#flags |= cv2.CALIB_FIX_FOCAL_LENGTH\n",
    "#flags |= cv2.CALIB_FIX_ASPECT_RATIO\n",
    "#flags |= cv2.CALIB_ZERO_TANGENT_DIST\n",
    "#flags |= cv2.CALIB_RATIONAL_MODEL\n",
    "#flags |= cv2.CALIB_SAME_FOCAL_LENGTH\n",
    "#flags |= cv2.CALIB_FIX_K3\n",
    "#flags |= cv2.CALIB_FIX_K4\n",
    "#flags |= cv2.CALIB_FIX_K5\n",
    "retS, MLS, dLS, MRS, dRS, R, T, E, F= cv2.stereoCalibrate(objpoints,\n",
    "                                                          imgpointsL,\n",
    "                                                          imgpointsR,\n",
    "                                                          mtxL,\n",
    "                                                          distL,\n",
    "                                                          mtxR,\n",
    "                                                          distR,\n",
    "                                                          ChessImaR.shape[::-1],\n",
    "                                                          criteria_stereo,\n",
    "                                                          flags)\n",
    "\n",
    "# StereoRectify function\n",
    "rectify_scale= 0 # if 0 image cropped, if 1 image nor cropped\n",
    "RL, RR, PL, PR, Q, roiL, roiR= cv2.stereoRectify(MLS, dLS, MRS, dRS,\n",
    "                                                 ChessImaR.shape[::-1], R, T,\n",
    "                                                 rectify_scale,(0,0))  # last paramater is alpha, if 0= croped, if 1= not croped\n",
    "# initUndistortRectifyMap function\n",
    "Left_Stereo_Map= cv2.initUndistortRectifyMap(MLS, dLS, RL, PL,\n",
    "                                             ChessImaR.shape[::-1], cv2.CV_16SC2)   # cv2.CV_16SC2 this format enables us the programme to work faster\n",
    "Right_Stereo_Map= cv2.initUndistortRectifyMap(MRS, dRS, RR, PR,\n",
    "                                              ChessImaR.shape[::-1], cv2.CV_16SC2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stereo Vision Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******************************************\n",
    "#***** Parameters for the StereoVision *****\n",
    "#*******************************************\n",
    "\n",
    "# Create StereoSGBM and prepare all parameters\n",
    "window_size = 3\n",
    "min_disp = 2\n",
    "num_disp = 130-min_disp\n",
    "stereo = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "    numDisparities = num_disp,\n",
    "    blockSize = window_size,\n",
    "    uniquenessRatio = 10,\n",
    "    speckleWindowSize = 100,\n",
    "    speckleRange = 32,\n",
    "    disp12MaxDiff = 5,\n",
    "    P1 = 8*3*window_size**2,\n",
    "    P2 = 32*3*window_size**2)\n",
    "\n",
    "# Used for the filtered image\n",
    "stereoR=cv2.ximgproc.createRightMatcher(stereo) # Create another stereo for right this time\n",
    "\n",
    "# WLS FILTER Parameters\n",
    "lmbda = 80000\n",
    "sigma = 1.8\n",
    "visual_multiplier = 1.0\n",
    " \n",
    "wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=stereo)\n",
    "wls_filter.setLambda(lmbda)\n",
    "wls_filter.setSigmaColor(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mat data type = 17 is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-a9a5afe8af9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# Show the Undistorted images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Both Images'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLeft_nice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRight_nice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Normal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mframeL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframeR\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# Convert from color(BGR) to gray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: mat data type = 17 is not supported"
     ]
    }
   ],
   "source": [
    "#*************************************\n",
    "#***** Starting the StereoVision *****\n",
    "#*************************************\n",
    "\n",
    "# Call the two cameras\n",
    "CamR= cv2.VideoCapture(0)   # Wenn 0 then Right Cam and wenn 2 Left Cam\n",
    "CamL= cv2.VideoCapture(2)\n",
    "\n",
    "while True:\n",
    "    # Start Reading Camera images\n",
    "    retR, frameR= CamR.read()\n",
    "    retL, frameL= CamL.read()\n",
    "\n",
    "    # Rectify the images on rotation and alignement\n",
    "        # Rectify the image using the calibration parameters found during the initialization\n",
    "    Left_nice= cv2.remap(frameL,Left_Stereo_Map[0],Left_Stereo_Map[1], cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)  \n",
    "    Right_nice= cv2.remap(frameR,Right_Stereo_Map[0],Right_Stereo_Map[1], cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "\n",
    "##    # Draw Red lines\n",
    "##    for line in range(0, int(Right_nice.shape[0]/20)): # Draw the Lines on the images Then numer of line is defines by the image Size/20\n",
    "##        Left_nice[line*20,:]= (0,0,255)\n",
    "##        Right_nice[line*20,:]= (0,0,255)\n",
    "##\n",
    "##    for line in range(0, int(frameR.shape[0]/20)): # Draw the Lines on the images Then numer of line is defines by the image Size/20\n",
    "##        frameL[line*20,:]= (0,255,0)\n",
    "##        frameR[line*20,:]= (0,255,0)    \n",
    "        \n",
    "    # Show the Undistorted images\n",
    "    cv2.imshow('Both Images', np.hstack([Left_nice, Right_nice]))\n",
    "    cv2.imshow('Normal', np.hstack([frameL, frameR]))\n",
    "\n",
    "    # Convert from color(BGR) to gray\n",
    "    grayR= cv2.cvtColor(Right_nice,cv2.COLOR_BGR2GRAY)\n",
    "    grayL= cv2.cvtColor(Left_nice,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute the 2 images for the Depth_image\n",
    "    disp= stereo.compute(grayL,grayR)#.astype(np.float32)/ 16\n",
    "    dispL= disp\n",
    "    dispR= stereoR.compute(grayR,grayL)\n",
    "    dispL= np.int16(dispL)\n",
    "    dispR= np.int16(dispR)\n",
    "\n",
    "    # Using the WLS filter\n",
    "    filteredImg= wls_filter.filter(dispL,grayL,None,dispR)\n",
    "    filteredImg = cv2.normalize(src=filteredImg, dst=filteredImg, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "    filteredImg = np.uint8(filteredImg)\n",
    "    #cv2.imshow('Disparity Map', filteredImg)\n",
    "    disp= ((disp.astype(np.float32)/ 16)-min_disp)/num_disp # Calculation allowing us to have 0 for the \n",
    "                                                            # most distant object able to detect\n",
    "\n",
    "##    # Resize the image for faster executions\n",
    "##    dispR= cv2.resize(disp,None,fx=0.7, fy=0.7, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # Filtering the Results with a closing filter\n",
    "    closing= cv2.morphologyEx(disp,cv2.MORPH_CLOSE, kernel) # Apply an morphological filter for closing little \"black\" holes in the picture(Remove noise) \n",
    "\n",
    "    # Colors map\n",
    "    dispc= (closing-closing.min())*255\n",
    "    dispC= dispc.astype(np.uint8)                                   # Convert the type of the matrix from float32 to uint8, this way you can show the results with the function cv2.imshow()\n",
    "    disp_Color= cv2.applyColorMap(dispC,cv2.COLORMAP_OCEAN)         # Change the Color of the Picture into an Ocean Color_Map\n",
    "    filt_Color= cv2.applyColorMap(filteredImg,cv2.COLORMAP_OCEAN) \n",
    "\n",
    "    # Show the result for the Depth_image\n",
    "    #cv2.imshow('Disparity', disp)\n",
    "    #cv2.imshow('Closing',closing)\n",
    "    #cv2.imshow('Color Depth',disp_Color)\n",
    "    cv2.imshow('Filtered Color Depth',filt_Color)\n",
    "\n",
    "    # Mouse click\n",
    "    cv2.setMouseCallback(\"Filtered Color Depth\",coords_mouse_disp,filt_Color)\n",
    "    \n",
    "    # End the Programme\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "    \n",
    "# Save excel\n",
    "##wb.save(\"data4.xlsx\")\n",
    "\n",
    "# Release the Cameras\n",
    "CamR.release()\n",
    "CamL.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "https://docs.opencv.org/3.4.1/dd/d53/tutorial_py_depthmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "img_dir2 = 'C:/Users/markl/startup/raw-images/stereoImages_wCheckerboard/'\n",
    "#imgL = cv2.imread(img_dir + 'L_Image'+t+'.jpg',0)\n",
    "#imgR = cv2.imread(img_dir + 'R_Image'+t+'.jpg',0)\n",
    "\n",
    "imgL = cv2.imread(img_dir2 + 'L_Image2.jpg',0)\n",
    "imgR = cv2.imread(img_dir2 + 'R_Image2.jpg',0)\n",
    "\n",
    "stereo = cv2.StereoBM_create(numDisparities=16 * 3, blockSize=5 * 5)\n",
    "disparity = stereo.compute(imgL,imgR)\n",
    "plt.imshow(disparity,'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "https://shkspr.mobi/blog/2018/04/reconstructing-3d-models-from-the-last-jedi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "filename='result'\n",
    "img_left = cv2.imread(img_dir2 + 'L_Image2.jpg')\n",
    "img_right = cv2.imread(img_dir2 + 'R_Image2.jpg')\n",
    "window_size = 15\n",
    "\n",
    "left_matcher = cv2.StereoSGBM_create(\n",
    "    minDisparity=0,\n",
    "    numDisparities=16,\n",
    "    blockSize=5,\n",
    "    P1=8 * 3 * window_size ** 2,\n",
    "    P2=32 * 3 * window_size ** 2,\n",
    "    # disp12MaxDiff=1,\n",
    "    # uniquenessRatio=15,\n",
    "    # speckleWindowSize=0,\n",
    "    # speckleRange=2,\n",
    "    # preFilterCap=63,\n",
    "    # mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY\n",
    ")\n",
    "\n",
    "right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)\n",
    "\n",
    "wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=left_matcher)\n",
    "wls_filter.setLambda(80000)\n",
    "wls_filter.setSigmaColor(1.2)\n",
    "\n",
    "disparity_left  = left_matcher.compute(img_left, img_right)\n",
    "disparity_right = right_matcher.compute(img_right, img_left)\n",
    "disparity_left  = np.int16(disparity_left)\n",
    "disparity_right = np.int16(disparity_right)\n",
    "filteredImg     = wls_filter.filter(disparity_left, img_left, None, disparity_right)\n",
    "\n",
    "depth_map = cv2.normalize(src=filteredImg, dst=filteredImg, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "depth_map = np.uint8(depth_map)\n",
    "depth_map = cv2.bitwise_not(depth_map) # Invert image. Optional depending on stereo pair\n",
    "cv2.imwrite(img_dir2+filename+\"-depth.png\",depth_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://timosam.com/python_opencv_depthimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import cv2\n",
    " \n",
    "print('loading images...')\n",
    "imgL = cv2.imread('imgL.jpg')  # downscale images for faster processing\n",
    "imgR = cv2.imread('imgR.jpg')\n",
    " \n",
    "# SGBM Parameters -----------------\n",
    "window_size = 3                     # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    " \n",
    "left_matcher = cv2.StereoSGBM_create(\n",
    "    minDisparity=0,\n",
    "    numDisparities=160,             # max_disp has to be dividable by 16 f. E. HH 192, 256\n",
    "    blockSize=5,\n",
    "    P1=8 * 3 * window_size ** 2,    # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "    P2=32 * 3 * window_size ** 2,\n",
    "    disp12MaxDiff=1,\n",
    "    uniquenessRatio=15,\n",
    "    speckleWindowSize=0,\n",
    "    speckleRange=2,\n",
    "    preFilterCap=63,\n",
    "    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY\n",
    ")\n",
    " \n",
    "right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)\n",
    " \n",
    "# FILTER Parameters\n",
    "lmbda = 80000\n",
    "sigma = 1.2\n",
    "visual_multiplier = 1.0\n",
    " \n",
    "wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=left_matcher)\n",
    "wls_filter.setLambda(lmbda)\n",
    "wls_filter.setSigmaColor(sigma)\n",
    " \n",
    "print('computing disparity...')\n",
    "displ = left_matcher.compute(imgL, imgR)  # .astype(np.float32)/16\n",
    "dispr = right_matcher.compute(imgR, imgL)  # .astype(np.float32)/16\n",
    "displ = np.int16(displ)\n",
    "dispr = np.int16(dispr)\n",
    "filteredImg = wls_filter.filter(displ, imgL, None, dispr)  # important to put \"imgL\" here!!!\n",
    " \n",
    "filteredImg = cv2.normalize(src=filteredImg, dst=filteredImg, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "filteredImg = np.uint8(filteredImg)\n",
    "cv2.imshow('Disparity Map', filteredImg)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
