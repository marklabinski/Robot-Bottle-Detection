{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV-Python tests\n",
    "https://github.com/jagracar/OpenCV-python-tests/tree/master/OpenCV-tutorials/cameraCalibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  0.04631991702911602\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-02e51b282e57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m# Display the final result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'chess board'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mundistortedImg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\py35\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Define the chess board rows and columns\n",
    "rows = 7\n",
    "cols = 6\n",
    "\n",
    "# Image directory\n",
    "img_dir = 'C:/Users/markl/startup/raw-images/Calibration/'\n",
    "\n",
    "# Set the termination criteria for the corner sub-pixel algorithm\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 30, 0.001)\n",
    "\n",
    "# Prepare the object points: (0,0,0), (1,0,0), (2,0,0), ..., (6,5,0). They are the same for all images\n",
    "objectPoints = np.zeros((rows * cols, 3), np.float32)\n",
    "objectPoints[:, :2] = np.mgrid[0:rows, 0:cols].T.reshape(-1, 2)\n",
    "\n",
    "# Create the arrays to store the object points and the image points\n",
    "objectPointsArray = []\n",
    "imgPointsArray = []\n",
    "\n",
    "# Loop over the image files\n",
    "for path in glob.glob(img_dir+'L_Image*.jpg'):\n",
    "    # Load the image and convert it to gray scale\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (rows, cols), None)\n",
    "\n",
    "    # Make sure the chess board pattern was found in the image\n",
    "    if ret:\n",
    "        # Refine the corner position\n",
    "        corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        \n",
    "        # Add the object points and the image points to the arrays\n",
    "        objectPointsArray.append(objectPoints)\n",
    "        imgPointsArray.append(corners)\n",
    "\n",
    "        # Draw the corners on the image\n",
    "        cv2.drawChessboardCorners(img, (rows, cols), corners, ret)\n",
    "    \n",
    "    # Display the image\n",
    "    cv2.imshow('chess board', img)\n",
    "    cv2.waitKey(500)\n",
    "\n",
    "# Calibrate the camera and save the results\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objectPointsArray, imgPointsArray, gray.shape[::-1], None, None)\n",
    "np.savez(img_dir+'calib.npz', mtx=mtx, dist=dist, rvecs=rvecs, tvecs=tvecs)\n",
    "\n",
    "# Print the camera calibration error\n",
    "error = 0\n",
    "\n",
    "for i in range(len(objectPointsArray)):\n",
    "    imgPoints, _ = cv2.projectPoints(objectPointsArray[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error += cv2.norm(imgPointsArray[i], imgPoints, cv2.NORM_L2) / len(imgPoints)\n",
    "\n",
    "print(\"Total error: \", error / len(objectPointsArray))\n",
    "\n",
    "# Load one of the test images\n",
    "img = cv2.imread(img_dir+'L_Image20.jpg')\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "# Obtain the new camera matrix and undistort the image\n",
    "newCameraMtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))\n",
    "undistortedImg = cv2.undistort(img, mtx, dist, None, newCameraMtx)\n",
    "\n",
    "# Crop the undistorted image\n",
    "x, y, w, h = roi\n",
    "undistortedImg = undistortedImg[y:y + h, x:x + w]\n",
    "\n",
    "# Display the final result\n",
    "cv2.imshow('chess board', np.hstack((img, undistortedImg)))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " Based on the following tutorial:\n",
    "   http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_calib3d/py_pose/py_pose.html\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Image directory\n",
    "img_dir = 'C:/Users/markl/startup/raw-images/Calibration/'\n",
    "\n",
    "# This function draws lines joining the given image points to the first chess board corner\n",
    "def draw(img, corners, imgPoints):\n",
    "    corner = tuple(corners[0].ravel())\n",
    "    img = cv2.line(img, corner, tuple(imgPoints[0].ravel()), (255, 0, 0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgPoints[1].ravel()), (0, 255, 0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgPoints[2].ravel()), (0, 0, 255), 5)\n",
    "    return img\n",
    "\n",
    "# Load the camera calibration data\n",
    "with np.load(img_dir+'calib.npz') as calibData:\n",
    "    mtx, dist, rvecs, tvecs = [calibData[i] for i in ('mtx', 'dist', 'rvecs', 'tvecs')]\n",
    "\n",
    "# Define the chess board rows and columns\n",
    "rows = 7\n",
    "cols = 6\n",
    "\n",
    "\n",
    "# Set the termination criteria for the corner sub-pixel algorithm\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 30, 0.001)\n",
    "\n",
    "# Prepare the object points: (0,0,0), (1,0,0), (2,0,0), ..., (6,5,0). They are the same for all images\n",
    "objectPoints = np.zeros((rows * cols, 1, 3), np.float32)\n",
    "objectPoints[:, :, :2] = np.mgrid[0:rows, 0:cols].T.reshape(-1, 1, 2)\n",
    "\n",
    "# Create the axis points\n",
    "axisPoints = np.float32([[3, 0, 0], [0, 3, 0], [0, 0, -3]]).reshape(-1, 3)\n",
    "\n",
    "# Loop over the image files\n",
    "for path in glob.glob(img_dir+'L_Image*.jpg'):\n",
    "    # Load the image and convert it to gray scale\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (rows, cols), None)\n",
    "\n",
    "    # Make sure the chess board pattern was found in the image\n",
    "    if ret:\n",
    "        # Refine the corner position\n",
    "        corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "        # Find the rotation and translation vectors\n",
    "        val, rvecs, tvecs, inliers = cv2.solvePnPRansac(objectPoints, corners, mtx, dist)\n",
    "\n",
    "        # Project the 3D axis points to the image plane\n",
    "        axisImgPoints, jac = cv2.projectPoints(axisPoints, rvecs, tvecs, mtx, dist)\n",
    "        \n",
    "        # Draw the axis lines\n",
    "        img = draw(img, corners, axisImgPoints)\n",
    "    \n",
    "    # Display the image\n",
    "    cv2.imshow('chess board', img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Epipolar Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    " Based on the following tutorial:\n",
    "   http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_calib3d/py_epipolar_geometry/py_epipolar_geometry.html\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib\n",
    "\n",
    "\n",
    "img_dir = 'C:/Users/markl/startup/raw-images/Calibration/'\n",
    "\n",
    "# Load the left and right images in gray scale\n",
    "imgLeft = cv2.imread(img_dir+'L_Image20.jpg',0)\n",
    "imgRight = cv2.imread(img_dir+'R_Image20.jpg',0)\n",
    "\n",
    "# Detect the SIFT key points and compute the descriptors for the two images\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "keyPointsLeft, descriptorsLeft = sift.detectAndCompute(imgLeft, None)\n",
    "keyPointsRight, descriptorsRight = sift.detectAndCompute(imgRight, None)\n",
    "\n",
    "# Create FLANN matcher object\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "indexParams = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "searchParams = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(indexParams, searchParams)\n",
    "\n",
    "# Match the descriptors (this crashes in OpenCV3.1)\n",
    "# See https://github.com/Itseez/opencv/issues/5667\n",
    "matches = flann.knnMatch(descriptorsLeft, descriptorsRight, k=2)\n",
    "\n",
    "# Apply ratio test\n",
    "goodMatches = []\n",
    "ptsLeft = []\n",
    "ptsRight = []\n",
    "\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.8 * n.distance:\n",
    "        goodMatches.append([m])\n",
    "        ptsLeft.append(keyPointsLeft[m.trainIdx].pt)\n",
    "        ptsRight.append(keyPointsRight[n.trainIdx].pt)\n",
    "\n",
    "ptsLeft = np.int32(ptsLeft)\n",
    "ptsRight = np.int32(ptsRight)\n",
    "F, mask = cv2.findFundamentalMat(ptsLeft, ptsRight, cv2.FM_LMEDS)\n",
    "\n",
    "# We select only inlier points\n",
    "ptsLeft = ptsLeft[mask.ravel() == 1]\n",
    "ptsRight = ptsRight[mask.ravel() == 1]\n",
    "\n",
    "def drawlines(img1, img2, lines, pts1, pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    r, c = img1.shape\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "    for r, pt1, pt2 in zip(lines, pts1, pts2):\n",
    "        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        x0, y0 = map(int, [0, -r[2] / r[1] ])\n",
    "        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1] ])\n",
    "        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 1)\n",
    "        img1 = cv2.circle(img1, tuple(pt1), 5, color, -1)\n",
    "        img2 = cv2.circle(img2, tuple(pt2), 5, color, -1)\n",
    "    return img1, img2\n",
    "\n",
    "# Find epilines corresponding to points in right image (second image) and\n",
    "# drawing its lines on left image\n",
    "linesLeft = cv2.computeCorrespondEpilines(ptsRight.reshape(-1, 1, 2), 2, F)\n",
    "linesLeft = linesLeft.reshape(-1, 3)\n",
    "img5, img6 = drawlines(imgLeft, imgRight, linesLeft, ptsLeft, ptsRight)\n",
    "\n",
    "# Find epilines corresponding to points in left image (first image) and\n",
    "# drawing its lines on right image\n",
    "linesRight = cv2.computeCorrespondEpilines(ptsLeft.reshape(-1, 1, 2), 1, F)\n",
    "linesRight = linesRight.reshape(-1, 3)\n",
    "img3, img4 = drawlines(imgRight, imgLeft, linesRight, ptsRight, ptsLeft)\n",
    "\n",
    "plt.subplot(121), plt.imshow(img5)\n",
    "plt.subplot(122), plt.imshow(img3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " Based on the following tutorial:\n",
    "   http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_calib3d/py_depthmap/py_depthmap.html\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load img directory 2\n",
    "img_dir2 = 'C:/Users/markl/startup/raw-images/Disparity/'\n",
    "# Load the left and right images in gray scale\n",
    "imgLeft = cv2.imread(img_dir2+'L_Image18.jpg',0)\n",
    "imgRight = cv2.imread(img_dir2+'R_Image18.jpg',0)\n",
    "\n",
    "\n",
    "#for disnum in range(0,17):\n",
    "#    for blksz in range(7,21,2):\n",
    "        \n",
    "        #print('numDisparities: {}, blockSize: {}'.format(disnum,blksz))\n",
    "        \n",
    "        # Initialize the stereo block matching object \n",
    "        stereo = cv2.StereoBM_create(numDisparities=128, blockSize=21)\n",
    "        stereo.setMinDisparity(4)\n",
    "        stereo.setNumDisparities(128)\n",
    "        stereo.setBlockSize(21)\n",
    "        stereo.setSpeckleRange(16)\n",
    "        stereo.setSpeckleWindowSize(45)\n",
    "        # Compute the disparity image\n",
    "        disparity = stereo.compute(imgLeft, imgRight)\n",
    "\n",
    "        # Normalize the image for representation\n",
    "        min = disparity.min()\n",
    "        max = disparity.max()\n",
    "        disparity = np.uint8(255 * (disparity - min) / (max - min))\n",
    "\n",
    "        # Display the result\n",
    "        #cv2.imshow('Disparity -  numDisparities: {}, blockSize: {}'.format(disnum,blksz), np.hstack((imgLeft, imgRight, disparity)))\n",
    "        cv2.imshow('Disparity -  numDisparities: {}, blockSize: {}'.format(disnum,blksz), disparity)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparity(self):\n",
    "        matcher = cv2.StereoBM_create(1024, 7)\n",
    "        disparity = matcher.compute(cv2.cvtColor(self.images[0], cv2.COLOR_BGR2GRAY),\n",
    "                                    cv2.cvtColor(self.images[1], cv2.COLOR_BGR2GRAY))\n",
    "        self.process_output(disparity) \n",
    "\n",
    "def readyStereoBM(roi1, roi2):\n",
    "    stereobm = cv2.StereoBM_create(numDisparities=112, blockSize=31)\n",
    "    stereobm.setPreFilterSize(31)#41\n",
    "    stereobm.setPreFilterType(cv2.STEREO_BM_PREFILTER_NORMALIZED_RESPONSE)\n",
    "    stereobm.setPreFilterCap(31)\n",
    "    stereobm.setTextureThreshold(10)\n",
    "    stereobm.setMinDisparity(0)\n",
    "    stereobm.setSpeckleWindowSize(100)\n",
    "    stereobm.setSpeckleRange(64)\n",
    "    stereobm.setUniquenessRatio(0)\n",
    "    stereobm.setROI1(roi1)\n",
    "    stereobm.setROI1(roi2)\n",
    "    return stereobm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
